{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep Learning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSfwjk-38XQH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "9df6ab16-1e25-4e91-bae8-f0ce4f8cfcf5"
      },
      "source": [
        "%tensorflow_version 1.15\n",
        "%matplotlib inline\n",
        "!pip install memory-profiler\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "print(tf.__version__)\n",
        "\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', \n",
        "    min_delta=0, \n",
        "    patience=3, \n",
        "    verbose=1, \n",
        "    mode='min',\n",
        ")\n",
        "\n",
        "class MyCallback(tf.keras.callbacks.Callback):\n",
        "  def on_train_end(self, logs={}):\n",
        "    self.send_email()\n",
        "\n",
        "  def send_email(self):\n",
        "    import smtplib\n",
        "    from email.mime.multipart import MIMEMultipart\n",
        "    from email.mime.text import MIMEText\n",
        "    mail_content = \"Training finished, check me after you finished your cup of coffee\"\n",
        "    #The mail addresses and password\n",
        "    sender_address = 'REDACTED : INPUT YOUR EMAIL HERE'\n",
        "    sender_pass = 'REDACTED : INPUT YOUR EMAIL PASSWORD HERE'\n",
        "    receiver_address = 'REDACTED : INPUT RECEIVER EMAIL ADDRESS'\n",
        "    #Setup the MIME\n",
        "    message = MIMEMultipart()\n",
        "    message['From'] = sender_address\n",
        "    message['To'] = receiver_address\n",
        "    message['Subject'] = 'Model Training is finished'   #The subject line\n",
        "    #The body and the attachments for the mail\n",
        "    message.attach(MIMEText(mail_content, 'plain'))\n",
        "    #Create SMTP session for sending the mail\n",
        "    session = smtplib.SMTP('smtp.gmail.com', 587) #use gmail with port\n",
        "    session.starttls() #enable security\n",
        "    session.login(sender_address, sender_pass) #login with mail_id and password\n",
        "    text = message.as_string()\n",
        "    session.sendmail(sender_address, receiver_address, text)\n",
        "    session.quit()\n",
        "    print('Mail Sent')\n",
        "\n",
        "\n",
        "callbacks = [early_stop, MyCallback()]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgUT5gQgffBl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "188e19af-b6ab-424d-dbd0-73b8d3f01bac"
      },
      "source": [
        "# Data Preprocessing\n",
        "\n",
        "vocab_size = 10000\n",
        "embedding_dim = 64\n",
        "max_length = 250\n",
        "trunc_type='post'\n",
        "padding_type='post'\n",
        "oov_token = \"<OOV>\"\n",
        "training_portion = .8\n",
        "\n",
        "def train_test_split(data, train_size):\n",
        "    train = data[:train_size]\n",
        "    test = data[train_size:]\n",
        "    return train, test\n",
        "\n",
        "df = pd.read_csv('/content/drive/My Drive/final.csv')\n",
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "df.head()\n",
        "\n",
        "train_size = int(len(df.product_name) * training_portion)\n",
        "\n",
        "train_text, test_text = train_test_split(df['product_name'], train_size)\n",
        "train_cat, test_cat = train_test_split(df['category'], train_size)\n",
        "\n",
        "tokenize = Tokenizer(num_words=vocab_size, char_level=False)\n",
        "tokenize.fit_on_texts(train_text) # fit tokenizer to our training text data\n",
        "\n",
        "x_train_sequences = tokenize.texts_to_sequences(train_text)\n",
        "x_test_sequences = tokenize.texts_to_sequences(test_text)\n",
        "\n",
        "x_train = pad_sequences(x_train_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "x_test = pad_sequences(x_test_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(train_cat)\n",
        "y_train = encoder.transform(train_cat)\n",
        "y_test = encoder.transform(test_cat)\n",
        "\n",
        "# Converts the labels to a one-hot representation\n",
        "num_classes = np.max(y_train) + 1\n",
        "print(num_classes)\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsmxECNH6Wmm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "bb5d458c-7539-4661-eae8-775c736603d5"
      },
      "source": [
        "# Build and Train Model\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size+1, embedding_dim, input_length=max_length),\n",
        "    #tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128)),\n",
        "    tf.keras.layers.GlobalAveragePooling1D(),\n",
        "    tf.keras.layers.Dense(1024, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(num_classes, activation='softmax'),\n",
        "    ])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=32,\n",
        "                    epochs=20,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=callbacks\n",
        "                    )\n",
        "\n",
        "score = model.evaluate(x_test, y_test,\n",
        "                       batch_size=32, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "text_labels = encoder.classes_ \n",
        "\n",
        "for i in range(10):\n",
        "    prediction = model.predict(np.array([x_test[i]]))\n",
        "    predicted_label = text_labels[np.argmax(prediction)]\n",
        "    print(test_text.iloc[i][:50], \"...\")\n",
        "    print('Actual label:' + test_cat.iloc[i])\n",
        "    print(\"Predicted label: \" + predicted_label + \"\\n\")  \n",
        "    \n",
        "\n",
        "import pickle\n",
        "model.save('/content/drive/My Drive/text_classification.h5', include_optimizer=True)\n",
        "\n",
        "encoder_filename = '/content/drive/My Drive/encoder.pickle'\n",
        "pickle.dump(encoder, open(encoder_filename, 'wb'))\n",
        "\n",
        "tokenizer_filename = '/content/drive/My Drive/tokenizer.pickle'\n",
        "pickle.dump(tokenize, open(tokenizer_filename, 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnMuXUx27m1y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "####\n",
        "# Load Saved Model\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "m = load_model('/content/drive/My Drive/text_classification.h5')\n",
        "encoder_filename = '/content/drive/My Drive/encoder.pickle'\n",
        "tokenizer_filename = '/content/drive/My Drive/tokenizer.pickle'\n",
        "\n",
        "loaded_encoder = pickle.load(open(encoder_filename, 'rb'))\n",
        "labels = loaded_encoder.classes_\n",
        "\n",
        "tokenizer = pickle.load(open(tokenizer_filename, 'rb'))\n",
        "\n",
        "txt_input = ['tea tree oil acne cream']\n",
        "txt_sentences = tokenizer.texts_to_sequences(txt_input)\n",
        "padded_input = pad_sequences(txt_sentences, maxlen=max_length, padding='post', truncating='post')\n",
        "#matrix_input = tokenize.texts_to_matrix(txt_input, mode='binary')\n",
        "\n",
        "prediction = m.predict(padded_input)\n",
        "predicted_label = labels[np.argmax(prediction)]\n",
        "\n",
        "print(predicted_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oD-9AdYCffLf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot Graph\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7VJwTB9ffOk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sr8SjrmhffRl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQCj8phYffU1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMtx-MCsffXp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDfuZczfffa5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLP1FQQ0ffd4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4yfS8u8ffhd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtMghp0KffkT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipywMl4QffoX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3x7bJMdjffsz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZfabogkffv0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wul1pHpUffzC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cs1nyfGgff1v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNJhbje5ff7a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbTc5EZCff_F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iQVbEgrff6J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}